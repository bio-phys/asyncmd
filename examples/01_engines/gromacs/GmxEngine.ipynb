{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gromacs engines\n",
    "This notebook showcases the use of the python classes used to steer gromacs from python. It will only work if the gromacs executables are available (e.g. in your `$PATH` variable).\n",
    "\n",
    "There are two main classes you will use together:\n",
    " - `asyncmd.gromacs.MDP`, a python class which parses a gromacs molecular dynamics parameter file (`.mdp`) and makes its content available via a dictionary-like interface\n",
    " - the `asyncmd.gromacs.GmxEngine` or the `asyncmd.gromacs.SlurmGmxEngine`, both share a common interface and are `async/await` enabled python wrappers to run gromacs locally or via the SLURM workload manager, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and some basic checks that everything is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# if using the module system to make gromacs and friends available:\n",
    "# check that they are loaded!\n",
    "#module list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/gromacs-2022.4/bin/gmx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# unix only, check that gmx is available\n",
    "which gmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not initialize SLURM cluster handling. If you are sure SLURM (sinfo/sacct/etc) is available try calling `asyncmd.config.set_slurm_settings()` with the appropriate arguments.\n"
     ]
    }
   ],
   "source": [
    "import asyncmd\n",
    "import asyncmd.gromacs as asyncgmx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: setup logging to be more verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglevel = \"WARN\"\n",
    "loglevel = \"INFO\"  # comment this line if you want more logging\n",
    "%config Application.log_level=loglevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "l = logging.getLogger(\"asyncmd\")\n",
    "l.setLevel(loglevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup working directory and the number of gromacs simulations to run in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_engines = 4\n",
    "\n",
    "scratch_dir = \"gmx_engine_wdirs\"\n",
    "wdirs = [os.path.join(scratch_dir, f\"engine_{i}\") for i in range(n_engines)]\n",
    "\n",
    "for d in wdirs:\n",
    "    if not os.path.isdir(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `asyncmd.gromacs.MDP`\n",
    "The `MDP` is a dictionary-like interface to a parsed gromacs molecular dynamics parameter file `.mdp` file to enable easy inspection and modification from python code. Most of the values are automatically cast to their respective types, e.g. `nsteps` will always be an `int` and `ref-t` will always be a list of `float`. The default for unknown parameters is a list of `str` to allow for the highest flexibility possible.\n",
    "\n",
    "The class supports writing of its (possibly changed) content to a new `.mdp` file by using its `.write()` method and also knows if its content has been changed since parsing the original `.mdp` file. It even supports the (undocumented) keyformat CHARMM-GUI uses in which all `-` are replaced by `_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one MDP object per engine, in principal we could use the same object but this way is more customizable,\n",
    "# e.g. we could want to modify our setup have the engines run at a different temperatures\n",
    "mdps = [asyncgmx.MDP(\"../../resources/gromacs/capped_alanine_dipeptide/md.mdp\") for _ in range(n_engines)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDP has been changed since parsing:  False\n",
      "Parsed content:\n",
      "---------------\n",
      "integrator  :  md\n",
      "dt  :  0.002\n",
      "nsteps  :  -1\n",
      "nstxout  :  20\n",
      "nstvout  :  20\n",
      "nstlog  :  20\n",
      "nstxout-compressed  :  0\n",
      "nstlist  :  50\n",
      "ns-type  :  grid\n",
      "cutoff-scheme  :  Verlet\n",
      "rlist  :  1.1\n",
      "coulombtype  :  PME\n",
      "rcoulomb  :  1.1\n",
      "rvdw  :  1.1\n",
      "Tcoupl  :  v-rescale\n",
      "tc-grps  :  ['Protein', 'SOL']\n",
      "tau-t  :  [0.5, 0.5]\n",
      "ref-t  :  [300.0, 300.0]\n",
      "Pcoupl  :  C-rescale\n",
      "tau-p  :  1.0\n",
      "compressibility  :  [4.5e-05]\n",
      "ref-p  :  [1.0]\n",
      "gen-vel  :  no\n",
      "constraints  :  h-bonds\n"
     ]
    }
   ],
   "source": [
    "# lets have a look at what is inside\n",
    "print(\"MDP has been changed since parsing: \", mdps[0].changed)\n",
    "print(\"Parsed content:\")\n",
    "print(\"---------------\")\n",
    "for key, val in mdps[0].items():\n",
    "    print(key, \" : \", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: \"Pcoupl = C-rescale\" needs gromacs version >= 2021\n",
    "I.e. if you are running a recent version of gromacs (>= 2021) you should comment the line below in which we set \"Pcoupl = Berendsen\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets set the xtc output frequency to 0 in all MDPs, we will use the trr trajectory\n",
    "# we will also increase the trr output interval by a bit and add the `continuation` parameter\n",
    "nstout = 200\n",
    "for i, mdp in enumerate(mdps):\n",
    "    if i == 0:\n",
    "        # Use something different for the first mdp\n",
    "        # Note that the nstout options all have the correct datatype (i.e. integer)\n",
    "        # so we can do inplace multiplication on it\n",
    "        mdp[\"nstvout\"] *= 50\n",
    "        mdp[\"nstxout\"] *= 50\n",
    "        mdp[\"nstlog\"] *= 50\n",
    "    else:\n",
    "        mdp['nstvout'] = nstout\n",
    "        mdp[\"nstxout\"] = nstout\n",
    "        mdp[\"nstlog\"] = nstout\n",
    "    \n",
    "    mdp[\"nstenergy\"] = nstout\n",
    "    mdp[\"nstxout-compressed\"] = 0\n",
    "    mdp[\"continuation\"] = \"yes\"  # dont apply constraints to the initial configuration\n",
    "    #mdp[\"Pcoupl\"] = \"Berendsen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDP has been changed since parsing:  True\n",
      "Parsed content:\n",
      "---------------\n",
      "integrator  :  md\n",
      "dt  :  0.002\n",
      "nsteps  :  -1\n",
      "nstxout  :  1000\n",
      "nstvout  :  1000\n",
      "nstlog  :  1000\n",
      "nstxout-compressed  :  0\n",
      "nstlist  :  50\n",
      "ns-type  :  grid\n",
      "cutoff-scheme  :  Verlet\n",
      "rlist  :  1.1\n",
      "coulombtype  :  PME\n",
      "rcoulomb  :  1.1\n",
      "rvdw  :  1.1\n",
      "Tcoupl  :  v-rescale\n",
      "tc-grps  :  ['Protein', 'SOL']\n",
      "tau-t  :  [0.5, 0.5]\n",
      "ref-t  :  [300.0, 300.0]\n",
      "Pcoupl  :  C-rescale\n",
      "tau-p  :  1.0\n",
      "compressibility  :  [4.5e-05]\n",
      "ref-p  :  [1.0]\n",
      "gen-vel  :  no\n",
      "constraints  :  h-bonds\n",
      "nstenergy  :  200\n",
      "continuation  :  yes\n"
     ]
    }
   ],
   "source": [
    "# have a look again\n",
    "print(\"MDP has been changed since parsing: \", mdps[0].changed)\n",
    "print(\"Parsed content:\")\n",
    "print(\"---------------\")\n",
    "for key, val in mdps[0].items():\n",
    "    print(key, \" : \", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `asyncmd.gromacs.GmxEngine` (and `asyncmd.gromacs.SlurmGmxEngine`)\n",
    "Both provide the functionality of the gromacs grompp and mdrun executables in one class, i.e. given molecular dynamics parameters and possibly an initial configuration they will setup and steer a MD run. Their interfaces differ only in the additional `sbatch_script` that the slurm engine requires at initialization time, they can otherwise be used interchangeably. Both engines need the gromacs executables to be available, specifically `gmx grompp` and `gmx mdrun`  (`gmx_mpi mdrun` for the `SlurmGmxEngine`). The `SlurmGmxEngine` naturally also must have access to the slurm executables, specifically `sbatch`, `sacct` and `scancel`. However all of these can be set either at initialization time via keyword arguments or globally as attributes to the uninitialized class.\n",
    "\n",
    "Each engine has a `prepare()` method (which will call `grompp`) and multiple methods to then run the simulation, namely `run()`, `run_walltime()` and `run_nsteps()`. The additional `prepare_from_files()` method can be used to continue a previous MD run from given `deffnm` and `workdir` (assuming all files/parts are there), note that it will (currently) not call `grompp` again and therefore assumes that the portable run input file (`.tpr`) allows for the continuation (i.e. has no or a sufficiently large integration step limit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create a list of identical engines to showcase the power of concurrent execution :)\n",
    "\n",
    "# we will use the `mdrun_extra_args` option to limit each engine to 2 threads\n",
    "# (the box is so small that otherwise the domain decomposition might fail)\n",
    "# depending on where you run and your gromacs version you might need to adapt this\n",
    "mdrun_extra_args = \"-nt 2\"\n",
    "\n",
    "engines = [asyncgmx.GmxEngine(mdconfig=mdp,\n",
    "                              gro_file=\"../../resources/gromacs/capped_alanine_dipeptide/conf.gro\",  # required\n",
    "                              top_file=\"../../resources/gromacs/capped_alanine_dipeptide/topol_amber99sbildn.top\",  # required\n",
    "                              # optional (can be omitted or None), however naturally without an index file\n",
    "                              # you can not reference custom groups in the .mdp-file or MDP object \n",
    "                              ndx_file=\"../../resources/gromacs/capped_alanine_dipeptide/index.ndx\",\n",
    "                              output_traj_type=\"trr\",  # optional, defaults to xtc\n",
    "                              mdrun_extra_args=mdrun_extra_args,\n",
    "                            )\n",
    "           for mdp in mdps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After setting the molecular dynamics parameters we can prepare a gromacs MD run.\n",
    "The gromacs engines `prepare()` method will call grompp, as with grompp you can use a specific starting configuration (the grompp `-t` option) or start from the structure file (`.gro`) the engine got at initialization.\n",
    "\n",
    "#### Lets prepare the first engine without a starting structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "e0 = engines[0]  # get it out of the list so tab-help/completion works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prepare method is an async def function (a coroutine) and must be awaited\n",
    "await e0.prepare(starting_configuration=None, workdir=wdirs[0], deffnm=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets prepare all other engines at once with the same initial configuration\n",
    "We can use asyncio.gather to run all coroutines concurrently, for prepare this does not make a big difference (since it is fast), but the same mechanism enables us to run all 4 gromacs engines in parallel later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an asyncmd.Trajectory of the initial configuration\n",
    "init_conf = asyncmd.Trajectory(trajectory_files=\"../../resources/gromacs/capped_alanine_dipeptide/conf_in_alphaR.trr\",\n",
    "                               structure_file=\"../../resources/gromacs/capped_alanine_dipeptide/conf.gro\",\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and prepare the engines (the return value of prepare is None)\n",
    "await asyncio.gather(*(e.prepare(starting_configuration=init_conf, workdir=wdir, deffnm=\"test\")\n",
    "                       for e, wdir in zip(engines[1:], wdirs[1:])\n",
    "                       )\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the engines for a number of steps each.\n",
    "We will first run the last engine in the list alone and then all 4 concurrently for the same number of steps to show off the power of the concurrent execution of the gromacs subprocesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # import time to be able to show off ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running one engine for 10000 integration steps took 1.9287 seconds.\n",
      "The produced trajectory (Trajectory(trajectory_files=gmx_engine_wdirs/engine_3/test.part0001.trr, structure_file=gmx_engine_wdirs/engine_3/test.tpr)) has a length of 51 frames.\n",
      "This length is the number of steps divided by the engines output frequency (=200).\n",
      "Note, that we are off by plus one because the initial configuration is in the trajectory for gromacs.\n",
      "Note also that this is only true when explicitly passing nsteps to the `run` methods, \n",
      "unfortunately the real relation between frames and steps done is a bit more involved...\n",
      "See the docstring for `GmxEngine.steps_done` if you are brave and want to know more ;)\n"
     ]
    }
   ],
   "source": [
    "nsteps = 10000\n",
    "\n",
    "# run one engine and time it\n",
    "start = time.time()\n",
    "# the engine will return an asyncmd.Trajectory with the produced trajectory (part)\n",
    "traj = await engines[-1].run_steps(nsteps=nsteps, steps_per_part=True)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running one engine for {nsteps} integration steps took {round(end - start, 4)} seconds.\")\n",
    "print(f\"The produced trajectory ({traj}) has a length of {len(traj)} frames.\")\n",
    "print(f\"This length is the number of steps divided by the engines output frequency (={engines[-1].nstout}).\")\n",
    "print(\"Note, that we are off by plus one because the initial configuration is in the trajectory for gromacs.\")\n",
    "print(\"Note also that this is only true when explicitly passing nsteps to the `run` methods, \")\n",
    "print(\"unfortunately the real relation between frames and steps done is a bit more involved...\")\n",
    "print(\"See the docstring for `GmxEngine.steps_done` if you are brave and want to know more ;)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all engines for 10000 integration steps took 5.5837 seconds.\n",
      "But now we have a list of 4 trajectories with 10000 steps each...\n",
      "Trajectory(trajectory_files=gmx_engine_wdirs/engine_0/test.part0001.trr, structure_file=gmx_engine_wdirs/engine_0/test.tpr) with length: 11\n",
      "Trajectory(trajectory_files=gmx_engine_wdirs/engine_1/test.part0001.trr, structure_file=gmx_engine_wdirs/engine_1/test.tpr) with length: 51\n",
      "Trajectory(trajectory_files=gmx_engine_wdirs/engine_2/test.part0001.trr, structure_file=gmx_engine_wdirs/engine_2/test.tpr) with length: 51\n",
      "Trajectory(trajectory_files=gmx_engine_wdirs/engine_3/test.part0002.trr, structure_file=gmx_engine_wdirs/engine_3/test.tpr) with length: 51\n"
     ]
    }
   ],
   "source": [
    "# run all engines at once and time it\n",
    "start = time.time()\n",
    "# Now each engine will return asyncmd.Trajectory with the produced trajectory (part)\n",
    "# i.e. trajs will be a list of trajectories (in the same order as the engines in the list)\n",
    "trajs = await asyncio.gather(*(e.run_steps(nsteps=nsteps, steps_per_part=True) for e in engines))\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running all engines for {nsteps} integration steps took {round(end - start, 4)} seconds.\")\n",
    "print(f\"But now we have a list of {len(trajs)} trajectories with {nsteps} steps each...\")\n",
    "for t in trajs:\n",
    "    print(t, f\"with length: {len(t)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note how the first engine has produced a different number of frames in the trajectory?__\n",
    "The reason is the different output frequency (`nstout`), so the same number of integration steps will result in a different number of frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `prepare_from_files` to initialize new engines and pick up where we left off with the 'old' ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the engines\n",
    "new_engines = [asyncgmx.GmxEngine(mdconfig=mdp,\n",
    "                                  gro_file=\"../../resources/gromacs/capped_alanine_dipeptide/conf.gro\",\n",
    "                                  top_file=\"../../resources/gromacs/capped_alanine_dipeptide/topol_amber99sbildn.top\",\n",
    "                                  ndx_file=\"../../resources/gromacs/capped_alanine_dipeptide/index.ndx\",\n",
    "                                  output_traj_type=\"trr\",  # need to specify that we are using trr because xtc is the default\n",
    "                                  mdrun_extra_args=mdrun_extra_args,  # again limit to 2 threads\n",
    "                                  )\n",
    "               for mdp in mdps]\n",
    "e0 = new_engines[0]  # get one out for the autocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and initialize with prepare_from_files\n",
    "await e0.prepare_from_files(workdir=wdirs[0], deffnm=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the others concurrent in one go\n",
    "await asyncio.gather(*(e.prepare_from_files(workdir=wdir, deffnm=\"test\")\n",
    "                       for e, wdir in zip(new_engines[1:], wdirs[1:])\n",
    "                       )\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can do another round of MD in all engines in parallel\n",
    "Note that the partnums indicate that we picked up exactly where we left of. We could additionally check using the trajectories `.last_step` and `.first_step` properties, compare and observe that the last step in the previous MD runs will be the first step in these here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all engines for 10000 integration steps took 5.6832 seconds.\n",
      "But now we have a list of 4 trajectories with 10000 steps each...\n",
      "Trajectory(trajectory_files=gmx_engine_wdirs/engine_0/test.part0002.trr, structure_file=gmx_engine_wdirs/engine_0/test.tpr) with length: 11\n",
      "Trajectory(trajectory_files=gmx_engine_wdirs/engine_1/test.part0002.trr, structure_file=gmx_engine_wdirs/engine_1/test.tpr) with length: 51\n",
      "Trajectory(trajectory_files=gmx_engine_wdirs/engine_2/test.part0002.trr, structure_file=gmx_engine_wdirs/engine_2/test.tpr) with length: 51\n",
      "Trajectory(trajectory_files=gmx_engine_wdirs/engine_3/test.part0003.trr, structure_file=gmx_engine_wdirs/engine_3/test.tpr) with length: 51\n"
     ]
    }
   ],
   "source": [
    "# run all engines at once and time it\n",
    "start = time.time()\n",
    "trajs = await asyncio.gather(*(e.run_steps(nsteps=nsteps, steps_per_part=True) for e in new_engines))\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running all engines for {nsteps} integration steps took {round(end - start, 4)} seconds.\")\n",
    "print(f\"But now we have a list of {len(trajs)} trajectories with {nsteps} steps each...\")\n",
    "for t in trajs:\n",
    "    print(t, f\"with length: {len(t)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for specified walltime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all engines for 0.02 h (=72.0 s) took 72.7034 seconds.\n"
     ]
    }
   ],
   "source": [
    "walltime = 0.02 # 0.01 h = 36 s\n",
    "\n",
    "# run all engines at once and time it\n",
    "start = time.time()\n",
    "trajs = await asyncio.gather(*(e.run_walltime(walltime) for e in new_engines))\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running all engines for {walltime} h (={walltime*60*60} s) took {round(end - start, 4)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for specified walltime or number of steps (depending on what is reached first)\n",
    "We can also use the generic `run()` method which takes one or both of the `walltime` and `nsteps` arguments, it will finish as soon as one of the conditions is fulfilled. As the `run_steps()` method it also accepts the `steps_per_part` argument making it particularly useful to run in chunks (of length walltime) but for a fixed total number of steps.\n",
    "\n",
    "Note that we can either check if `engine.steps_done < n_steps_desired` (as we do below) or call the `engine.run(nsteps=n_steps_desired)` method until it returns `None` instead of a trajectory object, which indicates that the total number of steps done in that engine is exactly the requested number of total steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178000, 178000, 178000, 188000]\n",
      "[True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([e.steps_done for e in new_engines])\n",
    "print([e.steps_done < (max([e.steps_done for e in new_engines]) + 20000) for e in new_engines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original nsteps = 208000\n",
      "Will run for 208000 steps in all engines!\n",
      "Ran for a total of 1 loops. It took us 13.6632 seconds.\n"
     ]
    }
   ],
   "source": [
    "walltime = 0.01 # 0.01 h = 36 s\n",
    "nsteps = max([e.steps_done for e in new_engines]) + 20000\n",
    "\n",
    "print(f\"Original nsteps = {nsteps}\")\n",
    "\n",
    "# make sure that nsteps is a multiple of nstout for all engines\n",
    "# (this is enforced when you run for a fixed number of steps to avoid stupid one-off errors that might happen\n",
    "#  because the frames and steps are not multiples of each other)\n",
    "perfect_nsteps = all([nsteps % e.nstout == 0 for e in engines])\n",
    "while not perfect_nsteps:\n",
    "    for e in engines:\n",
    "        if nsteps % e.nstout != 0:\n",
    "            nsteps += e.nstout - (nsteps % e.nstout)\n",
    "    perfect_nsteps = all([nsteps % e.nstout == 0 for e in engines])\n",
    "\n",
    "print(f\"Will run for {nsteps} steps in all engines!\")\n",
    "\n",
    "# now the actual trajectory generation\n",
    "all_trajs = []\n",
    "all_times = []\n",
    "while any([e.steps_done < nsteps for e in new_engines]):\n",
    "    # run all engines at once and time it\n",
    "    start = time.time()\n",
    "    trajs = await asyncio.gather(*(e.run(walltime=walltime, nsteps=nsteps, steps_per_part=False)\n",
    "                                   for e in new_engines\n",
    "                                   )\n",
    "                                 )\n",
    "    end = time.time()\n",
    "    all_trajs.append(trajs)\n",
    "    all_times.append(end-start)\n",
    "\n",
    "print(f\"Ran for a total of {len(all_times)} loops. It took us {round(sum(all_times), 4)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Trajectory(trajectory_files=gmx_engine_wdirs/engine_0/test.part0004.trr, structure_file=gmx_engine_wdirs/engine_0/test.tpr),\n",
       " Trajectory(trajectory_files=gmx_engine_wdirs/engine_1/test.part0004.trr, structure_file=gmx_engine_wdirs/engine_1/test.tpr),\n",
       " Trajectory(trajectory_files=gmx_engine_wdirs/engine_2/test.part0004.trr, structure_file=gmx_engine_wdirs/engine_2/test.tpr),\n",
       " Trajectory(trajectory_files=gmx_engine_wdirs/engine_3/test.part0005.trr, structure_file=gmx_engine_wdirs/engine_3/test.tpr)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the last engine could already have produced a `None` instead of a trajectory in the last iteration\n",
    "# (since it is some steps ahead of the others because we ran it alone at the beginning of the notebook)\n",
    "all_trajs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
